\documentclass{classrep}
\usepackage[utf8]{inputenc}
\usepackage{color}
\usepackage{graphicx}
\usepackage{float}
\usepackage{environ}
\usepackage{comment}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{amsthm}
\usepackage{longtable}
\usepackage{float}
\usepackage{lscape}
\usepackage{icomma}
{\theoremstyle{definition}
  \newtheorem{definition}{Definicja}
}

\studycycle{Informatyka, studia dzienne, I st.}
\coursesemester{VI}

\coursename{Komputerowe systemy rozpoznawania}
\courseyear{2018/2019}

\courseteacher{dr inż. Marcin Kacprowicz}
\coursegroup{poniedziałek, 14:10}

\author{
\studentinfo{Justyna Hubert}{210200} \and
\studentinfo{Karol Podlewski}{210294}
}

\title{Zadanie 2: Podsumowania lingwistyczne}
\svnurl{https://github.com/hubjust/KSR}

\begin{document}
\maketitle

\section{Cel}
Celem zadania było aplikacji desktopowej, która posiada charakter doradczy, generujący pewną ilość podsumowań lingwistycznych dla podanej bazy, a następnie przedstawia użytkownikowu wybrane - według zastosowanych miar jakości wyniki, czyli podsumowania lingwistyczne.

\section{Wprowadzenie}	
Zagadnieniem jakim zajmowaliśmy się w ramach projektu była analiza działania lingwistycznych podsumowań baz danych na zbiorach rozmytych. Zbiór rozmyty jest podstawowym pojęciem wykorzystywanym przy naszym zadaniu, zatem przytoczmy jego definicję:

\begin{definition}[Zbiór rozmyty typu I]
Niech \(\mathcal{X}\) będzie zbiorem, którego elementy interesują
nas w sposób bezpośredni (czyli ,,zbiorem zwykłym'' znanym z teorii mnogości).
Wówczas \emph{zbiorem rozmytym na uniwersum \(\mathcal{X}\)}
nazywamy każdy zbiór \(A\) postaci:
\[A = \bigcup_{x \in \mathcal{X}} \{(x,\, \mu_A(x))\},\]
gdzie \(\mu_A(x) : \mathcal{X} \to [0,\,1]\) nazywamy \emph{funkcją
przynależności do zbioru rozmytego \(A\)}.
\end{definition}

W celu określenia, czy element należy do zbioru wykorzystaliśmy funkcję przynależności. Określa ona stopień przynależności elementu do zbioru. W naszym projekcie skorzystaliśmy z funkcji przynależności trójkątnej oraz prostokątnej. Przytoczmy ich definicje:

\begin{definition}[Zbiór rozmyty o prostokątnej funkcji przynależności]
Zbiór rozmyty \(A\) typu I na uniwersum \(\mathbb{R}\) jest
\emph{liczbą rozmytą prostokątną o parametrach \(a, b\)} wtedy i tylko
wtedy, gdy \(a \leq b\) oraz:

\[\mu_A(x) = \begin{cases}
0                 & \mbox{gdy } x \in (-\infty,\, a], \\
1                 & \mbox{gdy } x \in (a,\, b), \\
0                 & \mbox{gdy } x \in [b,\, +\infty).
\end{cases}\]
\end{definition}

\vspace\baselineskip

\begin{definition}[Zbiór rozmyty o trójkątnej funkcji przynależności]
Zbiór rozmyty \(A\) typu I na uniwersum \(\mathbb{R}\) jest
\emph{liczbą rozmytą trójkątną o parametrach \(a, b, c\)} wtedy i tylko
wtedy, gdy \(a \leq b \leq c\) oraz:

\[\mu_A(x) = \begin{cases}
0                 & \mbox{gdy } x \in (-\infty,\, a], \\
(x - a) / (b - a) & \mbox{gdy } x \in (a,\, b), \\
1                 & \mbox{gdy } x = b, \\
(c - x) / (c - b) & \mbox{gdy } x \in (b,\, c), \\
0                 & \mbox{gdy } x \in [c,\, +\infty).
\end{cases}\]
\end{definition}

\vspace\baselineskip

Wyjaśnijmy także, czym jest lingwistyczne podsumowanie. Niech \(\mathcal{D}\) będzie bazą danych, czyli zbiorem \(m\)
krotek opisujących poszczególne rekordy (każdą \(i\)-tą krotkę
dla \(i=1 \ldots m\) będziemy oznaczać jako \(d_i\)). Każda
kolumna opisuje cechę pewnego typu. Cechę krotki możemy nazwać \emph{zmienną lingwistyczną}, a jej wartością może być konkretna liczba, ale może być to także rozmyta klasa (np. mało/trochę/dużo/sporo). Niech \(P\) będzie zbiorem rozmytym na uniwersum krotek bazy danych \(\mathcal{D}\),
który zawiera w sobie krotki posiadające pewną własność. Taki zbiór
może nam posłużyć jako podmiot podsumowania lingwistycznego (np. mężczyźni, kobiety, samochody, zawodnicy"). Bardzo ważnym elementem, wykorzystywanym we wszystkich rodzajach podsumowań
lingwistycznych, jest kwantyfikator oznaczany jako \(Q\).
Przykładami kwantyfikatorów mogą być: "około 10", "ponad 70"
(kwantyfikatory absolutne - zbiory rozmyte na uniwersum \(\mathbb{R}\)) lub "większość", "znikoma część"
(kwantyfikatory relatywne - zbiory rozmyte na uniwersum \([0,\, 1]\)).
Istotny dla nas będzie stopień przynależności \(P\) do \(Q\). Zdefiniujmy także sumaryzator
\(S_j\). Jest to zbiór rozmyty na zbiorze wartości przyjmowanych przez \(j\)-tą kolumnę bazy danych.
Np. gdyby krotki dotyczyły różnych osób, a jedną ze zmiennych lingwistycznych
były ich zarobki, to sumaryzatory mogłyby mieć postać "zarabia za mało",
"zarabia ponad 6400\,zł" itp.

\vspace\baselineskip

Wykorzystując powyższe elementy można skonstruować \textbf{lingwistyczne podsumowanie
bazy danych wg. Yagera}, czyli:
\[Q ~ P \mbox{ jest/są } S_j ~[T] ~\mbox{,}\]
gdzie \(T\) to stopień prawdziwości podsumowania.

\vspace\baselineskip

W celu rozszerzenie podsumowania lingwistycznego należy skorzystać ze złożonego sumaryztora. Sumę sumaryzatorów można w podsumowaniu lingwistycznym zapisać
za pomocą słowa "lub", zaś iloczyn za pomocą słowa "i".
W rezultacie \textbf{podsumowanie ze złożonym sumaryzatorem} może
mieć postać:
\[Q ~ P \mbox{ jest/są } S_1 \mbox{ i/lub } S_2 \mbox{ i/lub } \ldots \mbox{ i/lub } S_n  ~[T] ~\mbox{.}\]

\vspace\baselineskip

Innym sposobem rozszerzenia pojęcia podsumowań
jest zastosowanie kwalifikatora. Kwalifikator
\(W\) jest zbiorem rozmytym na \(\mathcal{D}\),
który opisuje w jakim stopniu krotki posiadają
pewną własność. Typowe przykłady to "[osoby] które są bezrobotne",
"[osoby] które są dziećmi". \textbf{Podsumowanie
z~kwalifikatorem} ma postać:
\[Q ~ P \mbox{ mających własność } W \mbox{ ma własność } S_j ~[T] ~\mbox{.}\]

\vspace\baselineskip

Aby określić jakość naszych podsumowaniań zaimplementowaliśmy poniższe miary jakości:

\subsection{\(T_1\) -- stopień prawdziwości}

Najbardziej naturalną miarą jakości podsumowania lingwistycznego
jest wprowadzony przez Yagera stopień prawdziwości.
Abstrahując od tego, czy sumaryzator \(S_j\) jest wynikiem
złożenia wielu sumaryzatorów czy nie, możemy obliczyć
sumę przynależności wszystkich rozważanych krotek do niego:
\[r = \sum_{i=1}^{m} \mu_{\mathrm{ce}(S_j)}(d_i) ~\mbox{,}\]
gdzie \(\mathrm{ce}(S_j)\) jest rozszerzeniem cylindrycznym
sumaryzatora \(S_j\), a \(m\) liczba wszystkich krotek.
Zatem dla kwantyfikatorów relatywnych stopnień
prawdziwości możemy zapisać jako \(T_1 = \mu_Q(\frac{r}{m})\),
zaś dla kwantyfikatorów absolutnych jako \(T_1 = \mu_Q(r)\).

\subsection{\(T_2\) -- stopień nieprecyzyjności}
Dla podsumowania z \(n\) sumaryzatorami \(S_1 \ldots S_n\)
(w szczególności dla \(n=1\)) możemy określić miarę
jakości podsumowania określaną jako stopień nieprecyzyjności,
definiowaną następującym wzorem:
\[T_2 = 1 - \left(\prod_{j=1}^{n} \mathrm{in}(S_j)\right)^{1/n} ~\mbox{.}\]
Wyrażenie \(\left(\prod_{j=1}^{n} \mathrm{in}(S_j)\right)^{1/n}\) to po prostu
średnia geometryczna ze stopni rozmycia wykorzystanych sumaryzatorów.

\subsection{\(T_3\) -- stopień pokrycia}
Stopień pokrycia \(T_3\) jest zdefiniowany dla podsumowań z kwalifikatorami, czyli tymi opartymi na drugiej formie ilościowych wyrażeń lingwistycznych
Stopień pokrycia T3 
Dla każdego \(i=1\ldots m\) (związanego z krotką \(d_i\) z bazy
danych) możemy zdefiniować:
\[
\begin{array}{l}
t_i = \begin{cases}
1 & \mbox{gdy } \mu_{\mathrm{ce}(S_j)}(d_i) > 0 ~ \wedge ~ \mu_{W}(d_i) > 0 \\
0 & \mbox{w przeciwnym wypadku.}
\end{cases} \\
h_i = \begin{cases}
1 & \mbox{gdy } \mu_{W}(d_i) > 0 \\
0 & \mbox{w przeciwnym wypadku.}
\end{cases}
\end{array}\]

Przy powyższych oznaczeniach:
\[T_3 = \frac{\sum_{i=1}^{m} t_i}{\sum_{i=1}^{m} h_i} ~\mbox{.}\]


\subsection{\(T_4\) -- stopień stosowności}
Dla podsumowania z \(n\) sumaryzatorami \(S_1 \ldots S_n\)
oraz \(m\) krotkami w bazie danych możemy wprowadzić oznaczenia:
\[g_{ij} = \begin{cases}
1 & \mbox{gdy } \mu_{\mathrm{ce}(S_j)}(d_i) > 0 \\
0 & \mbox{w przeciwnym wypadku.}
\end{cases}\]
oraz
\[r_j = \frac{\sum_{i=1}^{m} g_{ij}}{m} ~\mbox{.}\]
Wówczas możemy zapisać:
\[T_4 = \left|\left( \prod_{j=1}^{n} r_j \right) - T_3\right| ~\mbox{.}\]

\subsection{\(T_5\) -- długość podsumowania}
Dla podsumowania z \(n\) sumaryzatorami \(S_1 \ldots S_n\)
miarę długości podsumowania definiujemy jako:
\[T_5 = \left(\frac{1}{2}\right)^{n-1} ~\mbox{.}\]

\subsection{\(T_6\) -- stopień nieprecyzyjności kwantyfikatora}
Nazwy miar \(T_6\)--\(T_{10}\) można określić jako samoopisujące się,
więc przedstawienie wzoru wyczerpuje zagadnienie w stopniu wystarczającym
dla niniejszego sprawozdania:
\[T_6 = 1-\mathrm{in}(Q) ~\mbox{.}\]

\subsection{\(T_7\) -- stopień liczności kwantyfikatora}
W przeciwieństwie do \(T_6\), zamiast zliczać elementy z nośnika \(Q\),
policzymy moc zbioru rozmytego:
\[T_7 = 1-\frac{\card(Q)}{\card(\mathcal{X}_Q)} ~\mbox{.}\]

\subsection{\(T_8\) -- stopień liczności sumaryzatora}
Możemy mieć do czynienia z sumaryzatorem złożonym; wtedy,
podobnie jak przy poprzednich miarach, stosujemy średnią geometryczną.
Dla podsumowania z \(n\) sumaryzatorami \(S_1 \ldots S_n\):

\[T_8 = 1- \left(\prod_{j=1}^{n} \frac{\card(S_j)}{\card(\mathcal{X}_j)}\right) ~\mbox{.}\]

\subsection{\(T_9\) -- stopień nieprecyzyjności kwalifikatora}
Stopień precyzji kwalifikatora \(T_9\) jest oparty na drugiej formie podsumowań tzn.: Q obiektów będących/mających W jest/ma S, gdzie W jest reprezentowane przez zbiór rozmyty i jest kwalifikatorem. Definicja tej miary jest następująca:
\[T_9 = 1-\mathrm{in}(W) ~\mbox{.}\]

\subsection{\(T_{10}\) -- stopień liczności kwalifikatora}
Stopień kardynalności kwalifikatora \(T_{10}\) definiujemy jako:
\[T_{10} = 1-\frac{\card(W)}{\card(\mathcal{X}_g)} ~\mbox{.}\]\\
gdzie miara \card() jest dana tak jak we wcześniejszych sekcjach.

\subsection{\(T_{11}\) -- długość kwalifikatora}
Długość kwalifikatora \(T_{11}\) definiujemy następująco:
\[T_{11} = 2\left(\frac{1}{2}\right)^{\card({W})} ~\mbox{.}\]
gdzie \card(W) jest ilością zbiorów rozmytych, z których kwalifikator jest skomponowany. Im bardziej złożony kwalifikator tym jakość podsumowania gorsza.

\vspace\baselineskip

\section{Opis implementacji}
Program został stworzony w języku C\#. Graficzny interfejs użytkownika został stworzony przy  wykorzystaniu Windows Presentation Foundation. Logika aplikacji została odseparowana od GUI, w zgodzie ze wzorcem projektowym Model-view-viewmodel (MVVM), poprzez implementacje trzech projektów (Logic, ViewModel i GUI).

\subsection{Logic}

\section{Materiały i metody}

Do przeprowadzenia badań i generowania konkretnych podsumowań wykorzystaliśmy bazę danych dotyczącą przechowującą statystyki piłkarzy z gry Fifa 2019.Składa się ona z 15397 krotek znajdujących się w tabeli z 20 różnymi kolumnami - w ramach naszego projektu skorzystaliśmy tylko z 13. Przedstawiamy je pniżej:

\begin{itemize}
	\item Wiek
	\item Wzrost
	\item Waga
	\item Tempo
	\item Przyspieszenie
	\item Prędkość
	\item Dribbling
	\item Zręczność
	\item Balans
	\item Reakcje
	\item Kontrola piłki
	\item Opanowanie
	\item Precyzja
	\item Ustawienie się 
\end{itemize}

Każda z ww. kolumn jest typem całkowitym.

\section{Wyniki}

Poniższej umieszczone tabele oraz wykresy są wynikami przeprowadzonych przez nas eksperymentów.

\subsection{Wpływ liczby k sąsiadów oraz wyboru metryki na klasyfikację}

\begin{table}[H]
	\centering
	\begin{tabular}{c c c c} 
		\hline
		\textbf{k} & \textbf{places [\%]} & \textbf{topics [\%]} &  \textbf{authors [\%]} \\ [0.5ex] 
		\hline
		\hline 
		2 & 74.4 & 53.7 & 43.9 \\ 
		3 & 78.5 & 52.2 & 43.9 \\
		5 & 80.2 & 52.2 & 36.6 \\
		7 & 81.0 & 53.7 & 26.8 \\
		10 & 81.5 & 60.4 & 24.4 \\
		15 & 81.6 & 62.7 & 29.3 \\
		20 & 81.4 & 61.2 & 31.7 \\ 
		\hline
	\end{tabular}
	\caption{Skuteczność klasyfikacji dla metryki Euklidesowej dla pierwszego sposobu ekstrakcji}
\end{table}

\begin{table}[H]
	\centering
	\begin{tabular}{c c c c} 
		\hline
		\textbf{k} & \textbf{places [\%]} & \textbf{topics [\%]} &  \textbf{authors [\%]} \\ [0.5ex] 
		\hline
		\hline 
		2 & 75.4 & 56.7 & 36.6 \\ 
		3 & 79.4 & 56.7 & 39.0 \\
		5 & 81.0 & 61.2 & 36.6 \\
		7 & 81.3 & 59.0 & 31.7 \\
		10 & 81.9 & 64.9 & 24.4 \\
		15 & 82.0 & 64.9 & 29.3 \\
		20 & 82.1 & 63.4 & 29.3 \\ 
		\hline
	\end{tabular}
	\caption{Skuteczność klasyfikacji dla metryki ulicznej dla pierwszego sposobu ekstrakcji}
\end{table}

\begin{table}[H]
	\centering
	\begin{tabular}{c c c c} 
		\hline
		\textbf{k} & \textbf{places [\%]} & \textbf{topics [\%]} &  \textbf{authors [\%]} \\ [0.5ex] 
		\hline
		\hline 
		2 & 80.3 & 14.9 & 17.1 \\ 
		3 & 80.3 & 44.0 & 17.1 \\
		5 & 80.3 & 44.0 & 17.1 \\
		7 & 80.3 & 44.0 & 17.1 \\
		10 & 80.3 & 44.0 & 17.1 \\
		15 & 80.3 & 44.0 & 17.1 \\
		20 & 80.3 & 44.0 & 17.1 \\ 
		\hline
	\end{tabular}
	\caption{Skuteczność klasyfikacji dla metryki Czebyszewa dla pierwszego sposobu ekstrakcji}
\end{table}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{{Rysunki/TF-places.png}}
	\caption{Dane z Tabel 1-3 dla kategorii places}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{{Rysunki/TF-topics.png}}
	\caption{Dane z Tabel 1-3 dla kategorii topics}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{{Rysunki/TF-authors.png}}
	\caption{Dane z Tabel 1-3 dla kategorii authors (własne teksty)}
\end{figure}

\begin{table}[H]
	\centering
	\begin{tabular}{c c c c} 
		\hline
		\textbf{k} & \textbf{places [\%]} & \textbf{topics [\%]} &  \textbf{authors [\%]} \\ [0.5ex] 
		\hline
		\hline 
		2 & 79.0 & 63.4 & 22.0 \\ 
		3 & 82.0 & 64.2 & 19.5 \\
		5 & 82.1 & 59.0 & 29.3 \\
		7 & 83.3 & 62.1 & 22.0 \\
		10 & 82.0 & 64.9 & 26.8 \\
		15 & 81.9 & 67.9 & 24.4 \\
		20 & 81.1 & 67.1 & 17.1 \\ 
		\hline
	\end{tabular}
	\caption{Skuteczność klasyfikacji dla metryki Euklidesowej dla drugiego sposobu ekstrakcji}
\end{table}

\begin{table}[H]
	\centering
	\begin{tabular}{c c c c} 
		\hline
		\textbf{k} & \textbf{places [\%]} & \textbf{topics [\%]} &  \textbf{authors [\%]} \\ [0.5ex] 
		\hline
		\hline 
		2 & 80.2 & 59.7 & 22.0 \\ 
		3 & 82.4 & 65.7 & 19.5 \\
		5 & 82.6 & 67.2 & 29.3 \\
		7 & 83.3 & 67.2 & 22.0 \\
		10 & 82.6 & 67.2 & 26.8 \\
		15 & 82.1 & 67.2 & 24.4 \\
		20 & 81.6 & 67.9 & 17.1 \\ 
		\hline
	\end{tabular}
	\caption{Skuteczność klasyfikacji dla metryki ulicznej dla drugiego sposobu ekstrakcji}
\end{table}

\begin{table}[H]
	\centering
	\begin{tabular}{c c c c} 
		\hline
		\textbf{k} & \textbf{places [\%]} & \textbf{topics [\%]} &  \textbf{authors [\%]} \\ [0.5ex] 
		\hline
		\hline 
		2 & 77.0 & 14.9 & 17.1 \\ 
		3 & 77.0 & 44.0 & 17.1 \\
		5 & 77.0 & 44.0 & 17.1 \\
		7 & 77.0 & 44.0 & 17.1 \\
		10 & 77.0 & 44.0 & 17.1 \\
		15 & 77.0 & 44.0 & 17.1 \\
		20 & 77.0 & 44.0 & 17.1 \\ 
		\hline
	\end{tabular}
	\caption{Skuteczność klasyfikacji dla metryki Czebyszewa dla drugiego sposobu ekstrakcji}
\end{table}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{{Rysunki/TF-places.png}}
	\caption{Dane z Tabel 4-6 dla kategorii places}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{{Rysunki/TF-topics.png}}
	\caption{Dane z Tabel 4-6 dla kategorii topics}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{{Rysunki/TF-authors.png}}
	\caption{Dane z Tabel 4-6 dla kategorii authors (własne teksty)}
\end{figure}

\begin{table}[H]
	\centering
	\begin{tabular}{c c c c} 
		\hline
		\textbf{k} & \textbf{places [\%]} & \textbf{topics [\%]} &  \textbf{authors [\%]} \\ [0.5ex] 
		\hline
		\hline 
		2 & 69.5 & 47.8 & 44.8 \\ 
		3 & 75.3 & 53 & 53.7 \\
		5 & 78.3 & 47 & 48.8 \\
		7 & 79.4 & 48.5 & 63.4 \\
		10 & 80.2 & 49.3 & 63.4 \\
		15 & 80.5 & 47.8 & 58.5 \\
		20 & 80.7 & 44.8 & 53.7 \\ 
		\hline
	\end{tabular}
	\caption{Skuteczność klasyfikacji dla metryki Euklidesowej dla trzeciego sposobu ekstrakcji}
\end{table}

\begin{table}[H]
	\centering
	\begin{tabular}{c c c c} 
		\hline
		\textbf{k} & \textbf{places [\%]} & \textbf{topics [\%]} &  \textbf{authors [\%]} \\ [0.5ex] 
		\hline
		\hline 
		2 & 69 & 49.3 & 56.1 \\ 
		3 & 75.1 & 47 & 56.1 \\
		5 & 78.2 & 47 & 48.8 \\
		7 & 79.3 & 46.3 & 58.5 \\
		10 & 80 & 51.5 & 61 \\
		15 & 80.5 & 45.5 & 58.5 \\
		20 & 80.7 & 45.5 & 56.1 \\ 
		\hline
	\end{tabular}
	\caption{Skuteczność klasyfikacji dla metryki ulicznej dla trzeciego sposobu ekstrakcji}
\end{table}

\begin{table}[H]
	\centering
	\begin{tabular}{c c c c} 
		\hline
		\textbf{k} & \textbf{places [\%]} & \textbf{topics [\%]} &  \textbf{authors [\%]} \\ [0.5ex] 
		\hline
		\hline 
		2 & 80.3 & 14.9 & 17.1 \\ 
		3 & 80.4 & 44 & 17.1 \\
		5 & 80.5 & 44 & 17.1 \\
		7 & 80.6 & 44 & 17.1 \\
		10 & 80.7 & 44 & 17.1 \\
		15 & 80.8 & 44 & 17.1 \\
		20 & 80.9 & 44 & 17.1 \\ 
		\hline
	\end{tabular}Możliwość wniesienia i instalacji sprzętu
	\caption{Skuteczność klasyfikacji dla metryki Czebyszewa dla trzeciego sposobu ekstrakcji}
\end{table}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{{Rysunki/OWN-places.png}}
	\caption{Dane z Tabel 7-9 dla kategorii places}
\end{figure}

\begin{figure}[H]Możliwość wniesienia i instalacji sprzętu
	\centering
	\includegraphics[width=0.9\textwidth]{{Rysunki/OWN-topics.png}}
	\caption{Dane z Tabel 7-9 dla kategorii topics}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{{Rysunki/OWN-authors.png}}
	\caption{Dane z Tabel 7-9 dla kategorii authors (własne teksty)}
\end{figure}

\subsection{Wpływ podziału tekstów na zbiory treningowe i testowe na klasyfikację}

\begin{table}[H]
	\centering
	\begin{tabular}{c c c c} 
		\hline
		\textbf{k} & \textbf{80\%} & \textbf{60\%} &  \textbf{40\%} \\ [0.5ex] 
		\hline
		\hline 
		5 & 82.7 & 80.2 & 78.4 \\
		7 & 83.3 & 81.0 & 79.9 \\
		10 & 84.2 & 81.5 & 80.4 \\
		15 & 83.9 & 81.6 & 80.4 \\
		\hline
	\end{tabular}
	\caption{Skuteczność klasyfikacji dla pierwszego sposobu ekstrakcji, dla kategorii places}
\end{table}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{{Rysunki/TF-80-60-40-places.png}}
	\caption{Skuteczność klasyfikacji dla pierwszego sposobu ekstrakcji, dla kategorii places}
\end{figure}

\begin{table}[H]
	\centering
	\begin{tabular}{c c c c} 
		\hline
		\textbf{k} & \textbf{80\%} & \textbf{60\%} &  \textbf{40\%} \\ [0.5ex] 
		\hline
		\hline 
		7 & 56.7 & 53.7 & 62.7 \\
		10 & 59.7 & 60.4 & 62.2 \\
		15 & 58.2 & 62.7 & 64.7 \\
		20 & 62.7 & 61.2 & 64.7 \\
		\hline
	\end{tabular}
	\caption{Skuteczność klasyfikacji dla pierwszego sposobu ekstrakcji, dla kategorii topics}
\end{table}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{{Rysunki/TF-80-60-40-topics.png}}
	\caption{Skuteczność klasyfikacji dla pierwszego sposobu ekstrakcji, dla kategorii topics}
\end{figure}

\begin{table}[H]
	\centering
	\begin{tabular}{c c c c} 
		\hline
		\textbf{k} & \textbf{80\%} & \textbf{60\%} &  \textbf{40\%} \\ [0.5ex] 
		\hline
		\hline 
		2 & 19.0 & 43.9 & 38.7 \\
		3 & 19.0 & 43.9 & 37.1 \\
		5 & 23.8 & 36.6 & 29.0 \\
		7 & 14.3 & 26.8 & 32.3 \\
		\hline
	\end{tabular}
	\caption{Skuteczność klasyfikacji dla pierwszego sposobu ekstrakcji, dla kategorii authors}
\end{table}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{{Rysunki/TF-80-60-40-authors.png}}
	\caption{Skuteczność klasyfikacji dla pierwszego sposobu ekstrakcji, dla kategorii authors}
\end{figure}


\begin{table}[H]
	\centering
	\begin{tabular}{c c c c} 
		\hline
		\textbf{k} & \textbf{80\%} & \textbf{60\%} &  \textbf{40\%} \\ [0.5ex]
		\hline
		\hline 
		7 & 82.6 & 79.4 & 78.5 \\
		10 & 83.1 & 80.2 & 79.2 \\
		15 & 83.5 & 80.5 & 79.6 \\
		20 & 83.3 & 80.7 & 79.7 \\
		\hline
	\end{tabular}
	\caption{Skuteczność klasyfikacji dla drugiego sposobu ekstrakcji, dla kategorii places}
\end{table}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{{Rysunki/OWN-80-60-40-places.png}}
	\caption{Skuteczność klasyfikacji dla drugiego sposobu ekstrakcji, dla kategorii places}
\end{figure}

\begin{table}[H]
	\centering
	\begin{tabular}{c c c c} 
		\hline
		\textbf{k} & \textbf{80\%} & \textbf{60\%} &  \textbf{40\%} \\ [0.5ex]
		\hline
		\hline 
		3 & 55.2 & 53.0 & 43.3 \\
		5 & 55.2 & 47.0 & 43.8 \\
		7 & 55.2 & 48.5 & 42.3 \\
		10 & 55.2 & 49.3 & 40.8 \\
		\hline
	\end{tabular}
	\caption{Skuteczność klasyfikacji dla trzeciego sposobu ekstrakcji, dla kategorii topics}
\end{table}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{{Rysunki/OWN-80-60-40-topics.png}}
	\caption{Skuteczność klasyfikacji dla trzeciego sposobu ekstrakcji, dla kategorii topics}
\end{figure}

\begin{table}[H]
	\centering
	\begin{tabular}{c c c c} 
		\hline
		\textbf{k} & \textbf{80\%} & \textbf{60\%} &  \textbf{40\%} \\ [0.5ex]
		\hline
		\hline 
		7 & 71.4 & 63.4 & 46.8 \\
		10 & 66.7 & 63.4 & 48.4 \\
		15 & 71.4 & 58.5 & 50.0 \\
		20 & 71.4 & 53.7 &  33.9 \\
		\hline
	\end{tabular}
	\caption{Skuteczność klasyfikacji dla trzeciego sposobu ekstrakcji, dla kategorii authors}
\end{table}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{{Rysunki/OWN-80-60-40-authors.png}}
	\caption{Skuteczność klasyfikacji dla trzeciego sposobu ekstrakcji, dla kategorii authors}
\end{figure}

\subsection{Wpływ konkretnych cech na klasyfikację}

Na wykresach widoczne są następujące oznaczenia:
\begin{description}
	\item [$c_{1})$] Liczba słów,
	\item [$c_{2})$] Liczba słów, których długość nie przekracza 3 znaków,
	\item [$c_{3})$] Liczba słów, których długość zawiera się w zakresie 4-7 znaków,
	\item [$c_{4})$] Liczba słów, których długość przekracza 8 znaków,
	\item [$c_{5})$] Liczba unikalnych słów,
	\item [$c_{6})$] Liczba słów napisanych wielką literą,
	\item [$c_{7})$] liczba słów rozpoczynających się wielką literą. 
\end{description}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{{Rysunki/OWN-missing-topics.png}}
	\caption{Skuteczność klasyfikacji dla brakujących cech, dla kategorii topics}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{{Rysunki/OWN-chosen-topics.png}}
	\caption{Skuteczność klasyfikacji dla wybranych cech, dla kategorii topics}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{{Rysunki/OWN-set-topics.png}}
	\caption{Skuteczność klasyfikacji dla zestawu cech, dla kategorii topics}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{{Rysunki/OWN-missing-authors.png}}
	\caption{Skuteczność klasyfikacji dla brakujących cech, dla kategorii authors}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{{Rysunki/OWN-chosen-authors.png}}
	\caption{Skuteczność klasyfikacji dla wybranych cech, dla kategorii authors}
\end{figure}

\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\textwidth]{{Rysunki/OWN-set-authors.png}}
	\caption{Skuteczność klasyfikacji dla zestawu cech, dla kategorii authors}
\end{figure}

\subsection{Najlepsze wyniki}
\begin{table}[H]
	\centering
	\begin{tabular}{c c c c c} 
		\hline
		\textbf{Kategoria} & \textbf{Skuteczność} & \textbf{Metryka} & \textbf{Ekstrakcja} &  \textbf{k} \\ [0.5ex]
		\hline
		\hline 
		Places & 83.3\% & Euklidesowa & IDF & 7 \\
		Places & 83.3\% & Uliczna & IDF & 7 \\
		Topics & 67.9\% & Euklidesowa & IDF & 15 \\
		Topics & 67.9\% & Uliczna & IDF & 20 \\
		Authors & 43.9\% & Euklidesowa & TF & 2, 3 \\
		\hline
	\end{tabular}
	\caption{Tabela przedstawiająca najlepsze wyniki z pierwszego eksperymentu (4.1)}
\end{table}

\begin{table}[H]
	\centering
	\begin{tabular}{c c c c c} 
		\hline
		\textbf{Kategoria} & \textbf{Skuteczność} & \textbf{Zb. treningowy} & \textbf{Ekstrakcja} &  \textbf{k} \\ [0.5ex]
		\hline
		\hline 
		Topics & 64.73\% & 40\% & TF & 15, 20 \\
		Authors & 43.9\% & 60\% & TF & 2, 3 \\
		Topics & 55.2\% & 80\% & Własne cechy & 3-10 \\
		Authors & 71.4\% & 80\% & Własne cechy & 7, 15, 20 \\
		\hline
	\end{tabular}
	\caption{Tabela przedstawiająca najlepsze wyniki z drugiego eksperymentu (4.2)}
\end{table}

\begin{table}[H]
	\centering
	\begin{tabular}{c c c} 
		\hline
		\textbf{Kategoria} & \textbf{Skuteczność} & \textbf{Wykorzystane cechy} \\ [0.5ex]
		\hline
		\hline 
		Topics & 62,7\% & $c_{3}$, $c_{4}$, $c_{5}$, $c_{6}$, $c_{7}$ \\
		Authors & 76,2\% & $c_{3}$, $c_{4}$, $c_{5}$, $c_{6}$, $c_{7}$ \\
		\hline
	\end{tabular}
	\caption{Tabela przedstawiająca najlepsze wyniki z trzeciego eksperymentu (4.3)}
\end{table}

\section{Dyskusja}

\subsection{Wpływ liczby k sąsiadów oraz wyboru metryki na klasyfikację}
W przypadku wszystkich trzech sposobów ekstrakcji, metryka Euklidesowa oraz metryka uliczna osiągają bardzo podobne wyniki i nie jesteśmy w stanie stwierdzić, która z nich wykazuje lepszą skuteczność. Metryka Czebyszewa charakteryzuje się zdecydowanie słabszą zdolnością do klasyfikacji. Osiąga niższe wyniki, niż dwie wcześniej wspomniane metryki.
 \newline

W przypadku pierwszego i drugiego sposobu ekstrakcji cech dla kategorii topics i places, zauważyliśmy, że wraz ze wzrostem liczby k sąsiadów zwiększała się także skuteczność. Najsłabsze wyniki osiągane były dla k równego 2. Jeśli zaś chodzi o kategorię authors, najwyższa skuteczność wykazywała mała liczba k sąsiadów (od 2 do 3). Wyraźny spadek wyników zaobserwowaliśmy, gdy k równało się 10. Podczas eksperymentu trzeciego sposobu ekstrakcji cech zauważyliśmy bardzo zmienną skuteczność w przypadku zmiany liczby k sąsiadów w zależności od wybranych kategorii. Kategoria places osiąga najsłabsze wyniki przy małej liczbie sąsiadów, z kolei kategoria topics najlepsze. Zauważyliśmy, że najwyższe wyniki w kategorii authors osiągane są przy liczbie sąsiadów równej 7 oraz 10. 


\subsection{Wpływ podziału tekstów na zbiory treningowe i testowe na klasyfikację}
W przeważającej większości najwyższe wyniki osiągane były przy 80\% zbioru treningowego. Tylko w jednym przypadku użycie 40\% zbioru treningowego pozwoliło osiągnąć najwyższą skuteczności (pierwszy sposób ekstrakcji, kategoria topics). Zazwyczaj jednak ten dobór procentowy okazywał się być najsłabszym ze względu na niedouczenie. 
\newline

\subsection{Wpływ konkretnych cech na klasyfikację}
Podczas klasyfikacji dla kategorii topics, zauważyliśmy, że liczba słów oraz liczba słów, których długość nie przekracza 3 znaków mają negatywny wpływ na osiąganą skuteczność. Świadczyć może o tym fakt, iż bez ww. cech osiągnęliśmy najwyższą skuteczność. Dużo ważniejsze okazały się cechy związane z unikalnością słów oraz wielkimi literami. \newline

Podczas klasyfikacji dla kategorii authors najważniejsza okazała się cecha odpowiadająca za liczbę unikalnych słów. Bez niej skuteczność spadła z 71\% na 47\%. Podobnie jak w przypadku kategorii topics, cechy sprawdzające liczbę słów oraz liczbę krótkich słów osłabiały nasze wyniki - dzięki wyłączeniu ich, uzyskaliśmy wyższe wyniki niż w przypadku wszystkich cech. 

	
\section{Wnioski}
\begin{itemize}
	\item Liczba k sąsiadów ma spory wpływ na skuteczność klasyfikacji, jednak nie ma jednej, optymalnej wartości - zmiana metryki, podziału zbiorów czy klasyfikowanych kategorii może spowodować obniżenie wyników dla stałego k.
	\item Dla mniejszych zbiorów tekstowych lepiej sprawdzają się mniejsze wartości k sąsiadów, dla większych - wyższe wartości.
	\item Metryka Czebyszewa nie powinna być wykorzystywana w klasyfikacji tekstów, gdyż osiąga bardzo słabe wyniki.
	\item Istotny jest podział tekstów na zbiory testowe oraz treningowe. W przypadku zbyt małego zbioru treningowego osiągamy zjawisko niedouczenia, w przypadku zbyt dużego - przeuczenia.
	\item Cechy odpowiedzialne za liczbę słów oraz liczbę krótkich słów (do 3 znaków)  nie sprawdzają się przy klasyfikacji tekstów.
	\item Wektor cech powinien się składać z przynajmniej kilku cech, żeby osiągnąć większą skuteczność.
\end{itemize}

	

\begin{thebibliography}{}
\bibitem{adam}
Methods for the linguistic summarization of data - aplications of fuzzy sets and their extensions, Adam Niewiadomski, Akademicka Oficyna Wydawnicza EXIT, Warszawa 2008
\bibitem{AGH}
http://home.agh.edu.pl/~horzyk/lectures/miw/KNN.pdf
\bibitem{Stop Lista}
https://github.com/hklemp/dotnet-stop-words
\bibitem{Stemizacja}
http://snowball.tartarus.org/algorithms/english/stemmer.html
\end{thebibliography}
\end{document}
